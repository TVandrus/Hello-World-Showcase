# config passed to dagster celery executor def, and to dagster-celery workers
execution: 
  config: 
    broker: 'amqp://guest:guest@localhost:5672//'  # Optional[str]: The URL of the Celery broker
    backend: 'rpc://' # Optional[str]: The URL of the Celery results backend
    include: ['execution_patterns.ELT-graph'] # Optional[List[str]]: Modules every worker should import
    config_source: # Dict[str, Any]: Any additional parameters to pass to the workers
      broker_pool_limit: 10 
      broker_connection_timeout: 10

      result_backend: 'rpc://' 
      result_extended: True 
      #result_backend = 'db+postgresql://dev_user:dev_user@localhost:5432/development_db' 
      #result_backend_always_retry = True
      #result_backend_base_sleep_between_retries_ms = 1000
      #result_backend_max_retries = 10

      event_queue_ttl: 30

      worker_send_task_events: True  
      worker_lost_wait: 10
      worker_concurrency: 2 
      worker_prefetch_multiplier: 1 
      worker_cancel_long_running_tasks_on_connection_loss: True 

      task_always_eager: False 
      task_ignore_result: False 
      task_track_started: True
      task_send_sent_event: True 

      task_create_missing_queues: False 
      task_default_queue: dagster 
      task_default_exchange: dagster 
      #task_default_exchange_type: direct 
      task_default_routing_key: dagster
      task_default_priority: 1 
      task_queue_max_priority: 10 
      task_queues: 
        - dagster:
            name: dagster 
            routing_key: dagster.#
        - extract_queue:
            name: extract_queue 
        - loading_queue:
            name: loading_queue 
        - compute_queue: 
            name: compute_queue 
      task_routes: 
        - dagster.execute_plan: 
            queue: dagster 
        - 'dagster.#':
            queue: dagster 
        - 'extract_queue.#':
            queue: extract_queue

