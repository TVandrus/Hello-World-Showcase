{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string_similarity as fuzzy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo of a custom text fuzzy-matching algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_a = [\n",
    "    \"42 - 123 HelloWorld Ave, Waterloo ON, A2C 4E6\", \n",
    "    \"Unit 42 123 Hello World Avenue Waterloo ON A2C4E6\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an illustrative example of the use case for this string-comparison algorithm, and some of the issues that should be addressed by the design:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str.__eq__(example_a[0], example_a[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In just about any digital context, the two text strings from example_a are not equal. But, if asked whether or not those strings represent the same thing, or specifically in the case of the problem that motivated this algorithm 'do these two text representations refer to the same mailing address?' most human readers can say there is a high degree of confidence that they would in fact consider them as the same mailing address.\n",
    "\n",
    "Algorithms such as taking the Jaccard Similarity (used for Power Query fuzzy-joins in Excel) offer a more granular approach to identifying similar text compared to the binary equal/not-equal operators without adding an excess of additional complexity due to being computationally simple and existing as an off-the-shelf solution. For those reasons it has been included as the reference for matching-performance.\n",
    "\n",
    "My goal was to create a general-purpose tool that could accelerate an existing manual-review process for duplicate addresses between two systems where the digital representations were often not 'equal' in the trivial sense, but where there was a high incidence of duplicates that were just slightly off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naive equality, after stripping out spaces and standardizing letter-case\n",
    "def heuristic_isequal(s1: str, s2: str): \n",
    "    return str.__eq__(\n",
    "        s1.replace(\" \", \"\").upper(), \n",
    "        s2.replace(\" \", \"\").upper()\n",
    "    )\n",
    "\n",
    "# Jaccard Similarity = |intersection of characters| / |union of characters|\n",
    "#  debatable whether the pre-processing of text to be standard improves the signal-to-noise, or hinders it for this algorithm\n",
    "def jaccard_similarity(s1, s2):\n",
    "    s1 = s1.replace(\" \", \"\").upper()\n",
    "    s2 = s2.replace(\" \", \"\").upper()\n",
    "    return round(len(set(s1).intersection(set(s2))) / len(set(s1).union(set(s2))), ndigits=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example A: an example of several commonly-observed typos that prevent exact matching, yet a case where many humans share the intuition that they could very likely represent the same information (both being mailing addresses for the same physical residence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heuristic_isequal(example_a[0], example_a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard_similarity(example_a[0], example_a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzzy.string_compare(example_a[0], example_a[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to read the output from string_compare: \n",
    "\n",
    "An output of 0 indicates absolutely no similarity, which is incredibly unlikely in practical cases.\n",
    "\n",
    "A similarity score in the range (0.0, 0.6) indicates very low similarity, where manual reviewers would almost certainly conclude the text is not meaningfully the same.\n",
    "\n",
    "Similarity equal to 1.0 means an exact match. Cases where this algorithm claims an exact match but a naive equality check does not is due to the basic pre-processing added to the function implementation for convenience of the intended application\n",
    "\n",
    "Empirically, the boundary where the granularity of a 'clever' solution will separate from less sophisticated approaches is to reliably present ~0.90-0.99 when indicating \"very similar, ususally with few minor typos\", and <0.80 being the point where even if the input text has some indications of being the same, human reviewers would seriously question if it's a valid interpretation, relying heavily on other context to make a determination. Although arbitrary, it is worth noting that Excel's default fuzzy-match threshold is set to 0.80\n",
    "\n",
    "**A word on pre-processing:** \n",
    "By default, string_compare strips out all spaces and ignores case/capitalization. \n",
    "\n",
    "For the purpose of characterising the algorithm performance, all further examples will not focus on pre-processing that could be uniformly applied to any method. \n",
    "\n",
    "(Note: choosing assumptions/business rules for preprocessing is an extremely important step, even before comparing or choosing algorithms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Broadly speaking, the stated goal is that an inexact matching should implement the principle of \"Pairs of text/strings that are more similar should score higher, and pairs that are less similar should score lower\" such that the algorithm could sufficiently approximate an intuitive human judgement, allowing for increased automation of manual review processes.\n",
    "\n",
    "The next section will be a series of examples consisting of three text strings, intended to check/demonstrate the characteristics of each inexact algorithm. \n",
    "\n",
    "The first two should be rated more similar to each other (positive match), but the first and third should be less similar (negative match), to demonstrate the level of granularity that algorithm is able to display.\n",
    "Without imposing an arbitrary limit, the hope is to see \"similar\" pairings score >0.85 to be flagged for confirmation, and questionable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test(triplet, fn=fuzzy.string_compare):\n",
    "\t# given a list of three strings, compare the first and second, then first and third using the provided function\n",
    "\t# standard/concise format for executing comparative examples\n",
    "\tprint(\"similar pair: \", fn(triplet[0], triplet[1]), \n",
    "\t\t\" \\nVS differing pair: \", fn(triplet[0], triplet[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are all convey roughly the same information to a natural-language reader, but the naive equality test fails to indicate that.\n",
    "\n",
    "While it makes the point of how fragile exact matching is for comparing free-text entries, it does justify anything more sophisticated than some cleaning of the data according to business rules, and even the benchmark Jaccard method isn't necessary for this trivial example.\n",
    "\n",
    "The remaining examples will be of an adversarial nature seeking (within the realm of plausible real-world data) to expose weaknesses in the algorithms, and determine the minimum level of complexity to be robust/reliable.\n",
    "\n",
    "\n",
    "Example B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_b = [\n",
    "    \"Test String\", \n",
    "    \"TestString\", \n",
    "    \"test string\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test(example_b, str.__eq__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test(example_b, heuristic_isequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test(example_b, jaccard_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test(example_b, fuzzy.string_compare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstrate the algorithm characteristics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There were a series of guiding principals that motivated the design of a custom fuzzy-match algorithm. Specifically, there had to be characteristics that were desirable above and beyond the matching performance provided by any existing solution. Because otherwise, the practical solution would be to use an off-the-shelf tool that is more widely-known, and likely has implementations with better computational performance in the target environment. \n",
    "\n",
    "The original application was to be a VBA macro called in Excel workbooks, for use by an operational team of non-technical users on standard company-issued PCs. \n",
    "\n",
    "The original prototype was implemented in Julia for testing the compute-performance of the algorithm (due to the very low computational and dependency overhead of Julia compared to other high-level languages, the main cause of unexpectedly poor performance is poor algorithm design).\n",
    "\n",
    "This Python implementation is a later translation for compatibility with potential new use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Design Considerations (DC)**\n",
    "\n",
    "### DC I: \n",
    "Text (strings) that share most characters should be more similar, even if there is an ommission/addition between the pair\n",
    "\n",
    "Example C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_c = [\n",
    "    \"Service Ontario, Waterloo Street S, Waterloo, ON\", \n",
    "    \"Srvc Ontario, Water Street W, Waterloo ON\", \n",
    "    \"TD Waterhouse Inc, Welland Crescent, Toronto, Ontario\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test(example_c, fuzzy.string_compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test(example_c, jaccard_similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DC II: \n",
    "Implicitly, text addresses of a similar length should end up more similar, even if there is substantial overlap in the set of characters. The set operations used for Jaccard similarity are largely blind to differences in length. Not only does string_compare account for the overlap in characters, but specifically the number of instances of matches.\n",
    "\n",
    "Example D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_d = [\n",
    "    \"Quebec City JL International Airport, Québec City, Québec\",\n",
    "    \"Quebec City Jean-Lesage Int'l Airport, Québec City, Québec\",\n",
    "    \"Aéroport international Jacques Langlois de QQuuéebbeecc, Québec City Québec, Québec, Québec Canada\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test(example_d, fuzzy.string_compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test(example_d, jaccard_similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DC III: \n",
    "A 'bag-of-characters' approach like Jaccard without accounting for order is helpful in overlooking minor typos and ommissions (false-negative matches). Handling the strings as sets-of-characters is convenient, but that alone was not sufficiently sensitive for distinguishing actual differences (true-negative matches). \n",
    "To address this, beyond the number of matches found, the count of transpositions (matched characters that are out of order between the pair) is also factored into the final calculation of similarity\n",
    "While the motivation included comparing addresses between systems that did not have the same delineation/standardization/formatting or content of fields, it was valid to assume the parts of the addresses between systems were going to be in the same/similar order within the strings supplied to the function (ie unit, street, city, postal code)\n",
    "\n",
    "Example E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_e = [\n",
    "    \"Katherine\", \n",
    "    \"Kahterine\", \n",
    "    \"Kaetriannah\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test(example_e, fuzzy.string_compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test(example_e, jaccard_similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DC IV: \n",
    "Following the consideration of matching characters, length, and order, this motivated some concept of 'localized' inexact matching be implemented to better match the perspective of human readers of English. \n",
    "\n",
    "The final implementation included a method for acknowledging matching characters within similar/localized sections between strings, but also penalizing transpositions based on how many characters were out of order, and even disregarding matching characters if they were outside that localized section.\n",
    "\n",
    "This concept of localized inexact matching turned out to be highly informative to the manual reviewers to contrast between minor typos and major differences, and justified the effort to implement the changes to their workflow. And because there was nothing else available to offer these attributes in the format required, that justified my efforts to implement it.\n",
    "\n",
    "Example F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_f = [\n",
    "    \"the Sun life insurance company of Canada\", \n",
    "    \"Sun the life insurance company for Canada\", \n",
    "    \"Canada the Sun insurance company of life\", \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test(example_f, fuzzy.string_compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test(example_f, jaccard_similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utter Ridiculousness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just how closely does this mimic the human intuition for what is the 'same' text, when the text has clearly been mangled just up to but not beyond the point of being unrecognizable? \n",
    "\n",
    "To be clear, string_compare is in no way an attempt to capture/compare semantic meaning, and does not see text with the same meaning as being highly similar after it has been run through a thesaurus. \n",
    "\n",
    "But if this algorithm can seem to cue off the same structural indicators of similarity as human readers in a case artificially-designed to play upon the selective auto-correct in the brains of fluent English-readers, I consider that a remarkably strong endorsement for this application. \n",
    "\n",
    "Example G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_g = [\n",
    "    \"According to research at Cambridge Univeristy, it doesn't matter in what order the letters in a word are, the only important thing is that the first and last letters be at the right places.\",\n",
    "    \"Aoccdrnig to rseearch at Cmabrigde Uinervtisy, it deosn't mttaer in waht oredr the ltteers in a wrod are, the olny iprmoetnt tihng is taht the frist and lsat lteetrs be at the rghit pclaes.\",\n",
    "    \"The rset can be a toatl mses and you can sitll raed it wouthit porbelm. Tihs is bcuseae the huamn mnid deos not raed ervey lteter by istlef, but the wrod as a wlohe. Wreid, rhgit?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test(example_g, fuzzy.string_compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test(example_g, jaccard_similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beyond Ridiculous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Especially as the length of the text goes up, and more of the alphabet and common punctuation marks appear in both strings, Jaccard similarity will tend to consider that all long strings are really quite similar. In fact, this is even accelerated by the pre-processing steps removing characters and case differences, because they reduce the total set of possible characters that could be differences. \n",
    "\n",
    "In all fairness, this is fully outside the reasonable or appropriate applications of the Jaccard method as a text-similarity measure, and entering into the realm of natural language processing where document-level analysis techniques make more practical sense. This is meant to stress-test the robustness of string_compare \n",
    "\n",
    "Extending that to its unnatural conclusion, even a relatively short string breaks the benchmark method, while string_compare is still able to make a clear distinction:\n",
    "\n",
    "Example G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_h = [\n",
    "    \"The quick brown fox jumps over the lazy dog.\",\n",
    "    \"The quick brown foxes jumped over the lazy dog.\",\n",
    "    \"And now for something completely different. Beelzebub proved to be quite the joker in this text circus.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test(example_h, fuzzy.string_compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test(example_h, jaccard_similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expectation is that a better-performing algorithm will rate more-similar pairs higher, and less-similar pairs lower. \n",
    "Further, a well-behaved similarity function will impose less of a penalty as 'less meaningful' changes are added between the compared texts, but changes that substantially change how the text address is interpreted should drastically lower the similarity score.\n",
    "\n",
    "See if string_compare demonstrates this, based on texts that you consider to be more or less similar.\n",
    "\n",
    "Is there an adversarial manipulation that can cause string_compare to behave in violation of human intuition about whether two strings are \"similar\" or not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_1 = \"Put your example text here\"\n",
    "text_2 = \"Put our sample text there.\"\n",
    "text_3 = \"Enter something else here\"\n",
    "\n",
    "interactive_example = [text_1, text_2, text_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test(interactive_example, fuzzy.string_compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test(interactive_example, jaccard_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test(interactive_example, heuristic_isequal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify below code cell to customize string_compare parameters applied to the above inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test(interactive_example,\n",
    "\tlambda t1, t2: fuzzy.string_compare(\n",
    "\t\tt1, t2, \n",
    "\t\tstrip=[\" \", \"-\", \",\", \".\"], \n",
    "\t\tkeep_case=True, \n",
    "\t\tignore_short=5 \n",
    "\t)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The \"So What?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above sections sought to establish the implementation of string_compare as substantively more refined than other available tools (while fitting within the same strict confines of the enterprise business environment). \n",
    "\n",
    "TLDR: There was an existing business process that was greatly accelerated by having such a solution available, the original sophisticated solution had become unavailable, and the most recent simple tool was proving insufficient. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Foundation\n",
    "\n",
    "Delving into that application will yield the motivations of the current specification, but first it is worth highlighting the conceptual foundation of this project (Jaro-Winkler similarity https://en.wikipedia.org/wiki/Jaro%E2%80%93Winkler_distance) which brought it to my attention from among other common string distance functions: https://en.wikipedia.org/wiki/String_metric \n",
    "\n",
    "Matthew A Jaro (1989) - \"Advances in Record-Linkage Methodology as Applied to Matching the 1985 Census of Tampa, Florida\"\n",
    "\n",
    "To evaluate the coverage of the US Census against an independent and more rigourous survey of Tampa Florida, Jaro needed to more reliably identify links between the two sets of records, which were critically dependent on free text fields (ie names) as the main identifiers. The implemented solution calculated a distance considering matching instances of characters between strings, transposed matches, and limited the substring search range to half the length of the longer string.\n",
    "\n",
    "William E Winkler (1990) - \"The State of Record Linkage and Current Research Problems\"\n",
    "\n",
    "Winkler proposed an extension to Jaro's distance metric (as well as its application to record-matching) with an additional component to emphasize a common prefix between the texts (ie Katherine and Kathy have a common prefix of four characters, increasing the final similarity score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application \n",
    "\n",
    "In the case of a jointly-owned account, both owners must periodically receive certain disclosures/updates/statements, which at the time were mailed out to a street address. Often, joint-owners live at the same mailing address and share finances, and for the purpose of cutting expenses (and providing less clutter in the Client experience) a single copy/envelope is sent for both addressees. However, it is also common for two joint owners not to share the same residence, either due to a separated couple, or accounts that might be jointly held for other reasons (ie an RESP started with contributions from a grand-parent jointly held with one or more parents of the beneficiary child). \n",
    "\n",
    "If each owner became a Client of Sun Life independently at different times, the mailing address associated with each individual may have been entered differently even if they were/are referring to the same address. Additionally, there is a need to check an individual's address between systems (ie Retail vs Group) for a routine reconciliation that ensures both systems are up to date/consistent across all experiences a Client has with Sun Life.\n",
    "\n",
    "**Task:**\n",
    "\n",
    "Between complete addresses (unit/apt/suite, PO Box, street number, street name, postal code, city, province) in different formats and potentially inconsistent free-text entry, determine if the residence/mailing address would be the same, or not\n",
    "\n",
    "**Outcomes:** \n",
    "\n",
    "True-Positive - addresses are actually the same, condense documents to reduce costs and improve Client experience\n",
    "True-Negative - two different addresses require multiple mailed copies to meet regulatory requirements for disclosure \n",
    "False-Negative - two addresses are actually the same, but are indicated to be different; two identical copies get mailed to the same residence, but all regulatory requirements are met \n",
    "False-Positive - two addresses which are actually different are flagged as being the same, and only one mailing address receives the necessary documents -> failure to meet regulatory mandate\n",
    "\n",
    "**Existing Solution:** \n",
    "\n",
    "Concatenating all the applicable elements of the address into one string creates a high level of consistency between systems, and allows for a trivial equality comparison between addresses; every Positive indication was a True-Positive, meaning the risk of False-Positives was negated.\n",
    "\n",
    "Further, all of the Negative-matches were flagged as Negatives, which is desirable. The issue is that there was a very high rate of False-Negatives, where a true match was not flagged.\n",
    "\n",
    "To refine the classification, on a routine basis all the flagged non-matches were manually reviewed to see if there were any inexact matches that could be fixed and combined for mailing. A persistent pattern of very close matches emerged, of a sufficiently-high volume that combining them justified the person-hours for review/reconciliation (estimated 4-8 hrs, monthly), with the volume of Clients in the systems steadily increasing over time. Contributing to the tedium of this task was the fact that 99% of Negative pairs were 'not at all similar' or 'obviously the same' except for a few characters difference. \n",
    "\n",
    "The previous solution to automate this process was to submit each list of addresses via access to a Google Maps API to return the longitude/latitude co-ordinates of the full-text address, and determining address similarity based on the pair of numeric co-ordinates. When that option was no longer available, a new design was required.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm Design In-Depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are theoretical limitations to the robustness of the logic, and perhaps also quirks of the current Python implementation, as well as a need for computational performance benchmarking before the point of considering further applications.\n",
    "\n",
    "The range for local matches is determined as rounding down (square-root (length of the longer string) ) \n",
    "For two equal-length strings of length n: \n",
    "    worst-case of zero matching characters ~= n * sqrt(n) comparisons \n",
    "    best case of exactly matching strings = n comparisons\n",
    "\n",
    "\n",
    "Explore or evaluate in more detail by enabling the verbose details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_1v = \"Put your example text here\"\n",
    "text_2v = \"Put our sample text there.\"\n",
    "text_3v = \"Enter something else here\"\n",
    "\n",
    "interactive_example_v = [text_1v, text_2v, text_3v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test(interactive_example_v,\n",
    "\tlambda t1, t2: fuzzy.string_compare(\n",
    "\t\tt1, t2, \n",
    "\t\t#strip=[\" \"], \n",
    "\t\t#keep_case=False, \n",
    "\t\t#ignore_short=4,\n",
    "        verbose=True \n",
    "\t)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternative use of (1 - similarity) as a distance *metric*\n",
    "\n",
    "Note formal axioms of a *metric*:  \n",
    "- Dist between item a and itself = 0 (satisfied)  \n",
    "- Symmetry of Dist(a, b) = Dist(b, a) (satisfied) \n",
    "- Triangle inequality Dist(a, b) + Dist(b, c) >= Dist(a, c) (satisfied)\n",
    "\n",
    "So it counts as a metric, though as argued by Amos Tversky (\"Features of Similarity\", 1977) that is not terribly important for determining a useful quantification of similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_distance(s1, s2, \n",
    "\t\tstrip=[\" \"], \n",
    "        keep_case=False, \n",
    "        ignore_short=4, \n",
    "\t\tverbose=False): \n",
    "    return 1 - fuzzy.string_compare(\n",
    "\t\ts1=s1, s2=s2, \n",
    "\t\tstrip=strip, \n",
    "\t\tkeep_case=keep_case, \n",
    "\t\tignore_short=ignore_short, \n",
    "        verbose=verbose \n",
    "\t) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
